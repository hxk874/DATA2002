---
title: "Lab 02: Australian road fatalities"
date: "2024-08-08"
author: "Ellen Ebdrup"
output: 
  html_document: 
    ### IMPORTANT ###
    # self_contained: true # Creates a single HTML file as output
    code_folding: show # Code folding; allows you to show/hide code chunks
    ### USEFUL ###
    code_download: true # Includes a menu to download the code file
    ### OPTIONAL ###
    df_print: paged # Sets how dataframes are automatically printed
    theme: readable # Controls the font, colours, etc.
    toc: true # (Useful) Creates a table of contents!
    toc_float: true # table of contents at the side
    number_sections: false # (Optional) Puts numbers next to heading/subheadings
---

```{r}
library(dplyr)
library(tidyverse)
library(ggplot2)
```


```{r}
# fatalities data
fdata = readxl::read_excel("bitre_fatalities_jun2024.xlsx", 
                           sheet = 2, 
                           skip = 4, # there are 4 rows of nothing
                           na = c("","-9"), # replace empty cells with "-9"
                           guess_max = 1e6) %>%
  janitor::clean_names()
```

## 1. How are missing values recorded, and why might they occur?
```{r}
# crash data
cdata = fdata |> 
  dplyr::select(-road_user, -gender, -age, -age_group) %>% 
  # we only want distinct rows
  dplyr::distinct() |> 
  # Take the first row of each crash_id. Meaning that is there are dublicates of crash_id take the first one.
  dplyr::group_by(crash_id) |> 
  dplyr::slice(1) |> 
  dplyr::ungroup() |> 
  # Create a new column for hour from the time column.
  # mutate() can create, change or override columns
  dplyr::mutate(hour = lubridate::hour(time))

cdata
```

Is there any dublicates?
```{r}
cdata %>% 
    group_by(crash_id) %>% 
    filter(n() > 1)
```


## 2. How many fatalities occurred since 1989? How many fatal crashes have there been since 1989?

```{r}
nrow(cdata) 
# same as
cdata %>%
  group_by(crash_id) %>%
  filter(year >= 1989)
# same as
cdata = cdata %>% 
    group_by(crash_id) %>% 
    slice(1) %>% 
    ungroup()
```


## 3. What is the most common hour of the day for a fatal crash?
We made a new column in the first block like this: 
cdata = cdata %>% 
    mutate(hour = lubridate::hour(time))

It is during 15:00-16:00. See plot below
```{r}
cdata %>%
    ggplot() + aes(x= hour) + geom_bar() +
    labs(x= "Hour of day", y="Number of fatalities")
```

## 4. What is the most common day of the week for a fatal crash?
Simple version:
```{r}
cdata %>%
    ggplot() + aes(x= dayweek) + geom_bar()
```

Change to days in order using factors with levels:
```{r}
# change the days to factors
cdata = cdata %>%
    mutate(dayweek_new = factor(dayweek, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) 

cdata %>%
  ggplot() + aes(x= dayweek_new) + geom_bar()+
  labs(x="", y="Number of fatalities")
```


## 5. What is the most common month for a fatal crash?
Simple version:
```{r}
cdata %>%
    ggplot() + aes(x= month) + geom_bar()
```

Using factor:
```{r}
cdata = cdata %>%
    mutate(month_named = factor(month, levels = 1:12, labels=month.abb)) # build-in month vector
          
cdata %>%
    ggplot() + aes(x= month_named) + geom_bar() +
    labs(x="", y="Number of fatalities")
```


## 6. Are fatal crashes uniformly distributed across the months of the year? 
Filter the data down to one year (e.g. 2019) to do this test. 
You should write out a full hypothesis test and make an appropriate conclusion.
Step 1: Create a new R Project (e.g. call it Lab01).
Step 2: download the fatalities to June 2023 Excel file and save it into the R project folder.
Step 3: Open a new R Markdown file.

```{r}
mcount = cdata %>% 
  filter(year == 2019) %>% 
  dplyr::count(month_named)

mcount
```
1. Hypothesis 

$H_0 : p_1 = p_2= p_3= ... = p_{12} = \frac{1}{12}$ vs $H_1$ : At least one of the equalities doesn't hold.

2. Assumption
Observations are randomly selected & independent of each other and $e_i = np_i \geq 5 \forall i$. 

```{r}
mcount = mcount %>% 
  mutate(expected = (1/12) * sum(n))

mcount$expected >= 5
```

3. Test Statistic
$$T=\sum_{i=1}^{12} \frac{(Y_i - e_i)^2}{e_i} \sim x_{11}^2 \text{ Under } H_0$$

4. Observed Test Statistic
```{r}
Tstat = sum(((mcount$n - mcount$expected)^2)/mcount$expected)
Tstat
```
$$t_0=\sum_{i=1}^{12} \frac{(y_i - e_i)^2}{e_i} \sim x_{11}^2 \text{ Under } H_0 = 8.51$$
5. P-value
```{r}
1 - pchisq(Tstat, df = 11)
```
same as
```{r}
pchisq(Tstat, df = 11, lower.tail = FALSE)
```

$$P(T \geq t_0) = P( x_{11}^2 \geq 8.51) = 0.667$$
```{r}
chisq.test(mcount$n)
```
6. Decision
Since the p-value is greater than $\alpha$=0.05, we donâ€™t reject $H_0$, meaning that the data is consistent with the proposed uniform distribution.

