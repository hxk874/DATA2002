---
title: "DATA2x02 Assignment"
date: "`r Sys.Date()`"
author: "540940662"
output: 
  html_document:
    self_contained: true # Creates a single HTML file as output
    code_folding: hide # Code folding; allows you to show/hide code chunks
    code_download: true # Includes a menu to download the code file
    toc: true # (Optional) Creates a table of contents!
    toc_float: true # table of contents at the side
    number_sections: true # (Optional) Puts numbers next to heading/subheadings
    fig_caption: true

table-of-contents: true # (Optional) Creates a table of contents!
number-sections: true # (Optional) Puts numbers next to heading/subheadings
    
bibliography: [refs/bibliography.bibtex, refs/packages.bib]
---


```{r setup, message = FALSE}
# {r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

#| message: false
library(tidyverse)
library(dplyr)
library(stringr)
library(gendercoder)
library(ggplot2)
library(janitor)
library(hms)
library(ggthemes) 
theme_set(theme_grey())

# creates a file with the bibtex for packages used:
knitr::write_bib(c(.packages(),
                   "knitr", "rmarkdown"), "refs/packages.bib")
# extra bibliography for manually added references bibliography.bibtex
# ??

# data 
x = readxl::read_excel("data/DATA2x02_survey_2024_Responses.xlsx")
```


"Data Analytics: Learning from Data"


```{r}
# Load the cleaned data from the "data" folder
cleaned_data <- read.csv("data/cleaned_survey_data.csv")
```


# Introduction
< 1. Is this a random sample of DATA2X02 students? >

In this report we explore the results from a survey taken by 313 students from the units DATA2002 and DATA2902, 252 and 58 students respectively (with 3 students not specifying their unit) - corresponding to around 37% and 69% respectively which suggest that there was an uneven participation rate between the two groups. 
The original results can be found via this [link](https://docs.google.com/spreadsheets/d/1CR33C_oUu2QqbKWshnk5pP_-wwRIx8z9RCtWN7cVVWw/pub?output=xlsx) [@data2002survey]. 

The sample of participated student is not a random sample since it a) does represents random cross-section of all DATA2X02 students - hence the 37% and 69% participation percentage and b) the participation was optional, which leads potentials bias. See @fig-uni_year_units


```{r}
#| label: fig-uni_year_units
#| fig-cap: "Distribution among the participated students from the DATA2x02 units. Notice that 3 second year student didn't specify thier unit. The total number of participated students is 313."

# Create a bar plot
cleaned_data$university_year <- factor(cleaned_data$university_year,
                                       levels = c("First year", "Second year", "Third year","Fourth year", "Fifth or higher year"),
                                       exclude = NULL)  # This includes NA in the factor levels, treated as an additional level

ggplot(cleaned_data, aes(x = enrolled_unit, fill = university_year)) +
  geom_bar(position = "dodge") +
  labs(title = "Distribution of University Year by Enrolled Unit",
       x = "Enrolled Unit",
       y = "Count") +
  theme_minimal() +
  scale_fill_brewer(palette = "Paired", name = "University Year")  # Customize the legend title

```

< 2. What are the potential biases? >

Since it relies on students' willingness and availability to complete the survey, there might be a self-selection bias. This type of bias occurs when individuals decide whether to participate in the survey, which may result in over- or underrepresentation of certain types of students.
For example could we assume more engaged students participate more often. 

< Which variables are most likely to be subjected to this bias? >

The study habits variables are likely to be subjected to self-selection bias. This includes target grade, performance, study hours, academic personality, and university year - students who are more diligent or organized might be more likely to participate, skewing the data towards higher study hours or more consistent study routines.


< 3. Which questions needed improvement to generate useful data (e.g. in terms of the way the question was phrased or response validation)? >

The questions that needed the most improvement includes `height`, `shoe_size` and `usual_bedtime`. Common among these variables was that responses included different units which made the interpretation of them almost impossible. 
Height, being the least impossible of them, still gave reason to difficulties. Firstly, the units where very different. Some answered in cm/centimeter, m/meter, foot/ft, inches, signs(+, ', \backslash) or just numbers (with or without decimals) without specifying unit. Same goes for the shoe size, this variable was even harder to interpret because of the diversity of how countries define shoe size. Therefore we have no idea if size 10 is Australian, Japanese, European, Chinese and so on and if it is a woman or mans size since that also differs within.  
Overall these two variables beacuse of thier units, made the cleaning and interpretation very difficult. 
Lastly the variable `usual_bedtime` didn't specify if the time is given using the 12-hour or 24-hour clock. Therefore we can't know exactly if a student goes to bad at 6:30 pm or am? We could that 3:30 must be am, but we can't be certain and thus not let our own bias influence our interpretation of the data. 
Overall, after a lot of trying to untangle these variables, I decided not to use them in my tests.  


# Report structure

Firstly, we will investigate and clean the data. 
Secondly, we perform and report three hypothesis tests, ensuring that we cover different methods. 
Lastly, we will summarize the findings and see if we can make any conclusion based on the results from the tests. 



## Initial data processing

<changeing of column names... used Gartts>
As for the initial data processing, the provided guide from (@tarr2024) is used. 

The first thing to note is that the column names, while very descriptive are terrible for programming with. Let's fix that. We can store a copy of the column names in the vector `old_names`:


Before cleaning any data, we look through the column to investigate the magnitude of change needed.

In an external excel file, we wrote down which columns that needed further attention. In the following sub paragraphs, we will go though the cleaning of these columns. 

The columns not listed below, have also been cleaned in the omfang of for example adding none, N/A, other or removing data points in wrong type...  
Furthermore, we have changed all characters to be small letters and made sure that numbers within a column are of the same datatype (e.i. float, int)


## Cleaned Dataset

Initially I began cleaning all data until I realized only a whose used for the tests where supposed to be cleaned. I will go through the cleaning process of a selected handful of the features. In appendix the code for cleaning the rest of the features can be found. 













# Result

Identify 3 questions you can answer from the data and perform a hypothesis test for each question. The hypotheses should be of the same form as what we have covered in lectures. Give a motivation for why you selected these questions. 
Be sure to report the hypothesis testing workflow, interpret the results and mention any limitations in the data that may impact your findings. You may have mentioned this in general terms in the introduction, but be specific in the results section.

There needs to be some variety in the types of tests you implement:

- at least one test from module 1  
- at least one test from module 2  
- at least one test needs to be based on a resampling method (e.g. Monte Carlo or permutation test).






## Module 1

### wk01


**Chi-squared Goodness-of-fit Test**


The only data about gender at Usyd was from 2021. Here the ratio between female and male is 57:43. Lets check if the proportions of gender enrolled in DATA2x02 follows the same distribution. 

```{r}
# 1. Create a new variable 'gender_new' that categorizes into 'female', 'male', and 'other'
cleaned_data <- cleaned_data |> 
  mutate(gender_new = case_when(
    gender_clean == "Female" ~ "female",
    gender_clean == "Male" ~ "male",
    TRUE ~ "other"  # Assign 'other' to any remaining gender categories
  ))
unique(cleaned_data$gender_new)
# 2. Calculate the observed distribution of gender in the dataset
observed_gender <- table(cleaned_data$gender_new)
observed_gender_df <- as.data.frame(observed_gender)
observed_gender_df <- observed_gender_df |> 
  mutate(proportion = round((Freq / sum(Freq)), digits = 3)) |>
  mutate(exp_prop = c(female = 0.565, male = 0.425, other = 0.01))

observed_gender_df

# 4. Perform the Chi-squared Goodness-of-Fit test
chisq.test(x = observed_gender, p = observed_gender_df$exp_prop)
```

Result: reject $H_0$


**Two-sample $t$-test**

```{r}
# Two-Sample t-Test for independent samples
# Assuming 'used_r_before' is a factor indicating if students have used R ("Yes" or "No")
# and 'weekly_study_hours' is a numeric variable representing the number of study hours per week.

# Subsetting the data into two groups based on the R usage
group_r <- cleaned_data[cleaned_data$used_r_before == "Yes", ]
group_no_r <- cleaned_data[cleaned_data$used_r_before == "No", ]

# Performing the Two-Sample t-Test
t_test_results <- t.test(group_r$weekly_study_hours, group_no_r$weekly_study_hours, var.equal = TRUE)
t_test_results

```

Hypothesis: Are there differences in average daily sleep hours between males and females?
```{r}
# Subset male and female sleep hours
male_sleep <- cleaned_data$average_daily_sleep_clean[cleaned_data$gender_clean == "Male"]
female_sleep <- cleaned_data$average_daily_sleep_clean[cleaned_data$gender_clean == "Female"]

# Conduct a two-sample t-test
t_test_independent <- t.test(male_sleep, female_sleep, alternative = "two.sided")

# Output the results
print(t_test_independent)

```


$H_0 : \mu_1 = \mu_2$

```{r}
# Subset data for male and female
study_hours_male <- cleaned_data$weekly_study_hours[cleaned_data$gender_clean == "Male"]
study_hours_female <- cleaned_data$weekly_study_hours[cleaned_data$gender_clean == "Female"]

# Run t-test 
t.test(study_hours_male, study_hours_female, var.equal = TRUE)
t.test(study_hours_male, study_hours_female, var.equal = FALSE)
```
Result:
$t_0$ : A low t-value close to 0, such as 0.23476, indicates that the observed difference between the two group means is small.
p-value : Don't reject $H_0$ 
In this case, a p-value of 0.8146 is much greater than common significance levels (e.g., 0.05). This means there is no evidence to reject the null hypothesis. In other words, we fail to reject the null hypothesis that the mean study hours for males and females are equal.



```{r}
# Load necessary library
library(ggplot2)

# Creating histograms and Q-Q plots for each group within 'enrolled_unit'
enrolled_units <- unique(cleaned_data$enrolled_unit)

# Loop through each unique unit and plot
plots_list <- lapply(enrolled_units, function(unit) {
  data_subset <- subset(cleaned_data, enrolled_unit == unit)
  
  # Histogram
  p1 <- ggplot(data_subset, aes(x = weekly_study_hours)) +
    geom_histogram(bins = 15, fill = "blue", alpha = 0.7) +
    ggtitle(paste("Histogram -", unit))
  
  # Q-Q Plot
  p2 <- ggplot(data_subset, aes(sample = weekly_study_hours)) +
    stat_qq() +
    stat_qq_line(col = "red") +
    ggtitle(paste("Q-Q Plot -", unit))
  
  list(Histogram = p1, QQPlot = p2)
})

# Conduct Shapiro-Wilk test for each group, ensuring adequate sample size
shapiro_results <- sapply(enrolled_units, function(unit) {
  data_subset <- subset(cleaned_data, enrolled_unit == unit)
  
  if (nrow(data_subset) >= 3 && nrow(data_subset) <= 5000) {
    shapiro_test_result <- shapiro.test(data_subset$weekly_study_hours)$p.value
  } else {
    shapiro_test_result <- NA  # Assign NA if sample size is not within the valid range
  }
  
  return(shapiro_test_result)
})

names(shapiro_results) <- enrolled_units

# Return the list of plots and Shapiro-Wilk test results
list(Plots = plots_list, Shapiro_Wilk_Test_Results = shapiro_results)

```

Hypothesis: Do students who submit assignments on time study more on average compared to those who don’t?
```{r}
# Two-Sample t-Test (assuming normal distribution)
t.test(weekly_study_hours ~ enrolled_unit, data = cleaned_data)

```
normality check:


```{r}
# Wilcoxon Rank-Sum Test
wilcox.test(weekly_study_hours ~ enrolled_unit, data = cleaned_data)
```


**Simple Linear Regression**
Hypothesis: Does the number of weekly study hours predict the students' WAM (Weighted Average Mark)?
Simple linear regression assesses if a predictor variable has a linear relationship with a response variable.

```{r}
# Simple Linear Regression to predict WAM based on weekly study hours
lm_result <- lm(wam_clean ~ weekly_study_hours, data = cleaned_data)
summary(lm_result)

```


**ANOVA (Analysis of Variance)**

Avg exercise hours are the same for all countries

```{r}
# Perform ANOVA to compare sleep hours across relationship statuses
anova_result <- aov(weekly_exercise_hours ~ target_grade, data = cleaned_data)

# mean of e
mean_exercise_by_grade <- cleaned_data %>%
  group_by(target_grade) %>%
  summarise(mean_exercise_hours = round(mean(weekly_exercise_hours, na.rm = TRUE), digits = 2))
mean_exercise_by_grade

# Perform ANOVA to check if there is a significant difference between the groups 
anova_result <- aov(weekly_exercise_hours ~ target_grade, data = cleaned_data)
summary(anova_result)
```
Results:

- Residual Standard Error (= 52.49): This is the standard deviation of the residuals (within-group variation). It represents the average deviation of the observed weekly_exercise_hours from the predicted values.
indicates that there is substantial variability in weekly exercise hours within each grade group. This could imply that target_grade may not be a strong predictor of weekly exercise habits.

- Estimated Effects May Be Unbalanced: This message indicates that the group sizes for the different target_grade categories might not be equal, which can affect the precision of the ANOVA test.

- $t_0$ : F-value: 0.242 - This is the test statistic calculated for this ANOVA test, which compares the variance between the groups to the variance within the groups.
The small F-value suggests that the between-group variability (due to target_grade) is much smaller than the within-group variability (residuals).

- p-value: $0.914 > 0.05$ - This indicates that there is no statistically significant difference in weekly_exercise_hours among the different target_grade groups. In other words, the null hypothesis that there are no differences among the groups cannot be rejected.

**ANOVA (Analysis of Variance)**

Hypothesis: Is there a difference in the average weekly study hours based on the year of university (first, second, third, etc.)?

```{r}
# ANOVA to test differences in weekly study hours across different university years
anova_result <- aov(weekly_study_hours ~ university_year, data = cleaned_data)
summary(anova_result)

```


Is there an association between gender (gender_clean) and social media preference (social_media_clean)?

H0: There is no association between gender and social media preference.
H1: There is an association between gender and social media preference.

```{r}
cleaned_data$social_media_clean <- as.factor(cleaned_data$social_media_clean)
cleaned_data$average_daily_sleep_clean <- as.numeric(cleaned_data$average_daily_sleep_clean)

# Convert social media platform variable to a factor
cleaned_data$social_media_clean <- as.factor(cleaned_data$social_media_clean)

# Perform ANOVA
sleep_anova <- aov(average_daily_sleep_clean ~ social_media_clean, data = cleaned_data)


# Check if ANOVA is significant, then proceed with Tukey HSD test
# Assume we need to access the p-value from the summary output correctly
summary(sleep_anova)

# Pr(>F) = 0.718 > 0.05   => ANOVA not significant. Reject H0 
```

```{r}
# Creating a list of plots for each social media platform
plot_list <- lapply(levels(cleaned_data$social_media_clean), function(platform) {
  data_subset <- cleaned_data[cleaned_data$social_media_clean == platform, ]
  
  # Histogram with overlaid normal curve
  p1 <- ggplot(data_subset, aes(x = average_daily_sleep_clean)) +
    geom_histogram(aes(y = ..density..), bins = 15, fill = "skyblue", color = "black") +
    geom_density(color = "red") +
    ggtitle(paste("Histogram for", platform))

  # Q-Q plot
  p2 <- ggplot(data_subset, aes(sample = average_daily_sleep_clean)) +
    stat_qq() +
    stat_qq_line() +
    ggtitle(paste("Q-Q Plot for", platform))
  
  list(Histogram = p1, QQPlot = p2)
})

# Checking normality using Shapiro-Wilk test for each group
shapiro_results <- sapply(levels(cleaned_data$social_media_clean), function(platform) {
  data_subset <- cleaned_data[cleaned_data$social_media_clean == platform, ]
  shapiro.test(data_subset$average_daily_sleep_clean)$p.value
})

names(shapiro_results) <- levels(cleaned_data$social_media_clean)

# Output the results
list(Plots = plot_list, Shapiro_Wilk_Test_Results = shapiro_results)

```


```{r}
library(ggplot2)
ggplot(cleaned_data, aes(x = social_media_clean, y = average_daily_sleep_clean, fill = social_media_clean)) +
  geom_boxplot() +
  labs(title = "Sleep Hours by Social Media Preference", x = "Social Media Preference", y = "Average Daily Sleep (hours)") +
  theme_minimal()

```



**Chi-Square Test for Independence**

### wk02

**One-sample $t$-test**

$H_0$ : $\mu = \mu_0$

```{r}
t.test(cleaned_data$age_clean, mu = 25)
```

Hypothesis: Do students sleep significantly more or less than the recommended 8 hours per day?
```{r}
# One-Sample t-Test (testing against 8 hours of sleep)
t.test(cleaned_data$average_daily_sleep_clean, mu = 8)
```



**Chi-Square Test**
for testing association between categorical variables
```{r}
# Chi-Square Test of Independence
table_gender_living <- table(cleaned_data$gender_clean, cleaned_data$living_arrangements)
chisq.test(table_gender_living)
```



• Test for Mean (One-Sample t-Test)
```{r}
# Perform a one-sample t-test on weekly study hours
t.test(cleaned_data$weekly_study_hours, mu = 15, alternative = "two.sided")
```

• Test for Proportions (One-Sample Proportion Test)
```{r}

# Create a binary variable for gender_clean
gender_pref <- cleaned_data$gender_clean == "Female"
# Perform a one-sample proportion test
prop_test_gender <- prop.test(sum(gender_pref, na.rm = TRUE), length(gender_pref), p = 0.5)
print(prop_test_gender)

```

```{r}
# Create a contingency table
gender_rent_table <- table(cleaned_data$gender_clean, cleaned_data$pay_rent_clean)

# Perform Chi-Square Test for independence
chisq.test(gender_rent_table)

```


# Conclusion


# References

<div id="refs"></div>


