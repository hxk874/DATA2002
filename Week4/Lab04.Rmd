---
title: "Lab 04"
output: html_document
date: "2024-08-22"
---

# Personality type

1. Visualise the data. 

```{r}
counts = c(41, 52, 46, 61, 58, 72, 75, 63, 80, 65)
c_mat = matrix(counts, nrow = 2, byrow = TRUE)
colnames(c_mat) = c("Open", "Conscientious", "Extrovert", "Agreeable", "Neurotic")
rownames(c_mat) = c("Business", "Social Science")

# very simple display method, where you don't have to convert into a df first.
mosaicplot(t(c_mat))
```
```{r}
install.packages("reshape2")
```



```{r}
# convert into a df to display.
data.frame(
  counts = counts,
  major=c(rep("Business",5), rep("Social Science",5)), 
  personality= rep(c("Open", "Conscientious", "Extrovert", "Agreeable", "Neurotic"), 2))

df <- as.data.frame(c_mat)
df <- df |>
  tibble::rownames_to_column("major") |> 
  tidyr::pivot_longer(cols=!major, # columns that are not the "major" column
                      names_to = "personality",
                      values_to = "counts")
```

Plot data

```{r}
library(ggplot2)
df |> ggplot() + 
  aes(x = major, y=counts, fill = personality) +
  geom_col(position = "fill") + 
  scale_fill_brewer(palette = "Set1") +
  coord_flip() + 
  labs(y="% of students", x="Major", fill="Personality type") + 
  scale_y_continuous(labels = scales::percent) +
  guides(fill = guide_legend(reverse = TRUE)) +
  theme(legend.position = "top")
```

2. What is the appropriate test in this context? [I.e. a test of goodness of fit, homogeneity or independence.] 
Perform the test using a 5% level of significance.

```{r}
# check: expected must always be greater than 5:
chisq.test(c_mat)$expected

chisq.test(c_mat)
```
We don't reject the H0 hypothesis, since p-value = 0.5568 > 0.05


# Shocking

```{r}
x = matrix(c(12, 4, 5, 9), ncol = 2)
colnames(x) = c("Togehter", "Alone") # D
rownames(x) = c("High", "Low") # R

df <- data.frame(x)
df
```
1. If we’re picking between homogeneity and independence, which is more appropriate here?

Homogeneity 

## Perform test
At the 5% level of significance perform each of the following tests:

i) Fisher’s exact test

non-parametric. Doesnot assume an underlying distribution
```{r}
library(stats)
fisher.test(df)
```
p-value = 0.0634 > 0.05 => we don't reject $h_0$

ii)  A chi-squared test without a continuity correction
```{r}
chisq.test(df, correct = FALSE)
```
p-value = 0.0303 < 0.05 => we reject $h_0$



iii) A chi-squared test with a continuity correction.
```{r}
chisq.test(df, correct = TRUE)
```
p-value = 0.0723 > 0.05 => we don't reject $h_0$



iv)  A chi-squared test using a Monte Carlo p-value (i.e. using simulation).
```{r}
chisq.test(df, simulate.p.value = TRUE, B=20000)
```
p-value = 0.0619 > 0.05 => we don't reject $h_0$

Or perform it manually:

simulating tables 20,000 times. Keeps the same total for rows/cols
user-defined function from matrix
=> vector of matrices randomly generated

result to the right of hist => represents p-value

2. Do the results of the different tests agree?

No, ii) differs. 


3. Which are you most convinced by?

NOT ii) and iii)

The corrects is i)! almost always go with it.

4. Would it make sense to calculate a relative risk here? 

Calculate the odds ratio, confidence interval and provide an interpretation.

```{r}
mosaic::oddsRatio(df,verbose=TRUE)
```
If the 95% CI for an odds ratio does not include 1.0, then the odds ratio is considered to be statistically significant at the 5% level.

OR => significant


# Asbestos


```{r}
asbestos = matrix(c(310, 212, 21, 25, 7, 36, 158, 35, 102, 
                    35, 0, 9, 17, 49, 51, 0, 0, 4, 18, 28), nrow = 5)
colnames(asbestos) = c("None", "Grade 1", "Grade 2", "Grade 3")
rownames(asbestos) = c("0-9", "10-19", "20-29", "30-39", "40+")
y = asbestos |> as.data.frame() |> 
  tibble::rownames_to_column(var = "years") |> 
  tidyr::gather(key = grade, value = count, -years)
y$grade = factor(y$grade, levels = c("None", "Grade 1", "Grade 2", "Grade 3"), ordered = TRUE)
ggplot(y, aes(x = years, y = count, fill = grade)) + 
  geom_bar(stat = "identity") + 
  theme_bw(base_size = 16) + 
  scale_fill_brewer(palette = "Set1") + 
  labs(fill = "", y = "Count", x = "Occupational exposure (yrs)")
```

1. Adapt the ggplot2 code above such that the y-axis is a proportion within each exposure length group. Does it look like there’s a relationship between the two variables?

```{r}

y = asbestos |> as.data.frame() |> 
  tibble::rownames_to_column(var = "years") |> 
  tidyr::gather(key = grade, value = count, -years)

y$grade = factor(y$grade, levels = c("None", "Grade 1", "Grade 2", "Grade 3"), ordered = TRUE)
ggplot(y, aes(x = years, y = count, fill = grade)) + 
  geom_bar(stat = "identity", position = "fill") +  
  theme_bw(base_size = 16) + 
  scale_fill_brewer(palette = "Set1") + 
  labs(fill = "", y = "Count", x = "Occupational exposure (yrs)")
```



2. Use the function chisq.test() to perform a standard chi-squared test of independence to determine whether there exists a statistically significant association between years of exposure to asbestos fibres and the severity of asbestosis that they were diagnosed with.

We cant use chi test, since expected is < 5 at the rightmost column
=> p-value = 0 < 0.05 => we reject the $H_0$

3. Use x = r2dtable(____) to randomly generate a contingency table with the same row and column totals as asbestos. Perform a chi-squared test and extract the test statistic using chisq.test(x[[1]])$statistic.


4. By using the r2dtable() function, perform a Monte-Carlo simulation to determine the p-value for the chi-squared test of independence. Generate 10,000 bootstrap resamples. Note: if doing this in an Rmd script, you might want to wrap your chisq.test(___)$statistic in suppressWarnings() so they don’t slow down your computer, e.g. suppressWarnings(chisq.test(___)$statistic). Plot a histogram of your Monte Carlo test statistics.


5. Use the chisq.test() function to perform a Monte-Carlo simulation that obtains a p-value. Do so using 10,000 bootstrap resamples.




