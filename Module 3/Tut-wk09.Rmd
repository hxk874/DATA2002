---
title: "Week 9 Lab"
date: "`r Sys.Date()`"
author: "Tutor: Sanghyun Kim"
output: 
  html_document: 
    ### IMPORTANT ###
    # self_contained: true # Creates a single HTML file as output
    code_folding: hide # Code folding; allows you to show/hide code chunks
    ### USEFUL ###
    code_download: true # Includes a menu to download the code file
    ### OPTIONAL ###
    df_print: paged # Sets how dataframes are automatically printed
    theme: readable # Controls the font, colours, etc.
    toc: true # (Useful) Creates a table of contents!
    toc_float: true # table of contents at the side
    number_sections: false # (Optional) Puts numbers next to heading/subheadings
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

```{r}
library(tidyverse)
```

# Lecture recap

## Simultaneous confidence intervals

A 95% confidence interval for a **single** population contrast $\sum_{i=1}^{g}c_i\mu_i$ (where $\sum_{i=1}^{g}c_i=0$) is of the form:

$$\sum_{i=1}^{g}c_i\bar{y}_i\pm m\left(\hat{\sigma}\sqrt{\sum_{i=1}^{g}\frac{c_i^2}{n_i}}\right)$$

where the multiplier $m$ is the upper 2.5% quantile from the $t_{N-g}$ distribution (recall $N$ is the total sample size); the quantity in round brackets is the standard error. When the model is correct this procedure ‚Äúworks‚Äù 95% of the time in repeated experiments.

To keep the $k$ simultaneous coverage probability at $100(1-\alpha)\%$, we can make individual confidence intervals <u>wider</u> using a larger critical value $m$.

However if we are constructing several of these at once, while each one individually may work 95% of the time, having all of them ‚Äúwork‚Äù (simultaneously) is not guaranteed to the same degree. We can fix this **by increasing the multiplier** $m$. We have discussed 3 different approaches:

### The Bonferroni method

If we are constructing $k$ simultaneous $100(1-\alpha)$% confidence intervals, instead of using the upper $\alpha/2$ quantile, we use the upper $\alpha/2k$ quantile, i.e. as if we were constructing $100(1-\alpha/k)$% individual intervals. This procedure is in general conservative i.e. the resultant true confidence level is typically greater than desired (i.e. the multiplier is bigger than it needs to be).

‚ö†Ô∏è However, the Bonferroni method is conservative when $k$ is very large, as we discussed in week 8.

### Tukey's method

Tukey's method provides the exact multiplier one needs when:

- we're looking at all possible comparisons and
- the sample sizes are all the same

When these two conditions hold, it's the best we can do (i.e., it gives the smallest multiplier $m$ that does the job). *When the sample sizes are unequal* it's conservative (although possibly less so than the corresponding Bonferroni multiplier.)


### Scheff√©‚Äôs method

Scheff√©‚Äôs method provides the exact multiplier one needs when considering **all possible contrasts**, and thus, permits ‚Äúunlimited data snooping‚Äù. The multiplier is taken from the $\sqrt{(g-1)F}$ distribution, where here $F$ denotes the distribution of the corresponding $F$-statistic (i.e., $F_{g-1,N-g}$). This multiplier is thus conservative when considering only a finite number of contrasts, but again may be smaller than the corresponding Bonferroni multiplier.

\
\

## ANOVA Contrasts

The One-way ANOVA $F$-test allows us to test whether at least one pair of group has different population group means.

$$H_0:\ \ \mu_1 = \mu_2 = \ ...\ = \mu_g \ \ \ vs \ \ \ H_1: \ \text{at least one}\ \mu_i \ne \mu_j\ \ \ (i \ne j)$$

‚ö†Ô∏è But it doesn't tell us which pair of population group means is different.

üßê What if we want to know which particular pair of groups has different population means?

üëâ **ANOVA Contrasts**

‚Äª A contrast is a <u>linear combination of variables where the coefficients sum to 0</u>.

$$\sum_{i=1}^{g}c_i\mu_i \ \ \text{such that}\ \sum_{i=1}^{g}c_i=0$$


## Two-sample $t$-test for an ANOVA contrast

The random sample contrast follows a normal distribution:

$$\sum_{i=1}^gc_i\bar{Y}_{i\bullet}\sim N\left(\sum_{i=1}^gc_i\mu_i\ ,\ \sigma^2\sum_{i=1}^g\frac{c_i^2}{n_i}\right)$$

Then the standardised version is:

$$Z=\frac{\sum_{i=1}^{g}c_i\bar{Y}_{i\bullet}-\sum_{i=1}^{g}c_i\mu_i}{\sigma\sqrt{\sum_{i=1}^g\frac{c_i^2}{n_i}}}\sim N\left(0,1\right)$$

As $\sigma$ is unknown (a population parameter), we estimate $\sigma$ with $\hat{\sigma}=\sqrt{RMS}=\sqrt{\frac{RSS}{N-g}}$.

Note that under $H_0: \mu_i = \mu_j$, $\sum_{i=1}^{g}c_i\mu_i=0$. Therefore, the test statistic is:

$$T=\frac{\sum_{i=1}^gc_i\bar{Y}_{i\bullet}}{\hat{\sigma}\sqrt{\sum_{i=1}^g\frac{c_i^2}{n_i}}}\sim t_{N-g} \ \ \text{under}\ H_0$$

### $t$-test

1. **Hypotheses**
$$H_0: \mu_i=\mu_j\ \ \text{vs}\ \ H_1: \mu_i\ne\mu_j$$

2. **Assumptions**

- Observations are independent within each group
- Both populations are normally distributed
- Both groups have an equal variance: $\sigma_i=\sigma_j=\sigma$

3. **Observed Test Statistic**

$$T=\frac{\sum_{i=1}^gc_i\bar{Y}_{i\bullet}}{\hat{\sigma}\sqrt{\sum_{i=1}^g\frac{c_i^2}{n_i}}}\sim t_{N-g}$$

4. **P-value**

$$2P(T\ge |t_0|) = 2P(t_{N-g}\ge |t_0|)$$

5. **Decision**

|           Reject $H_0$ if $p<\alpha$  

\

### Confidence Interval

Alternatively, we can construct a 95% confidence interval for a population contrast using a critical value $m$ such that $\alpha = 0.05$.

$$P\left(-m\le \frac{\sum^{g}_{i=1}c_i\bar{Y}_{i\bullet}-\sum^{g}_{i=1}c_i\mu_i}{\hat{\sigma}\sqrt{\sum^{g}_{i=1}\frac{c_i^2}{n_i}}}\le m \right)=0.95$$

$$P\left(-m\cdot\hat{\sigma}\sqrt{\sum^{g}_{i=1}\frac{c_i^2}{n_i}}\le \sum^{g}_{i=1}c_i\bar{Y}_{i\bullet}-\sum^{g}_{i=1}c_i\mu_i\le m\cdot\hat{\sigma}\sqrt{\sum^{g}_{i=1}\frac{c_i^2}{n_i}}\right)=0.95$$

$$P\left(\sum^{g}_{i=1}c_i\bar{Y}_{i\bullet}-m\cdot\hat{\sigma}\sqrt{\sum^{g}_{i=1}\frac{c_i^2}{n_i}}\le \sum^{g}_{i=1}c_i\mu_i\le \sum^{g}_{i=1}c_i\bar{Y}_{i\bullet}+m\cdot\hat{\sigma}\sqrt{\sum^{g}_{i=1}\frac{c_i^2}{n_i}}\right)=0.95$$

Thus, the 95% confidence interval for a population contrast is:

$$\text{95% CI}=\sum_{i=1}^gc_i\bar{Y}_{i\bullet}\pm m\cdot\hat{\sigma}\sqrt{\sum_{i=1}^g\frac{c_i^2}{n_i}}$$


‚ö†Ô∏è Caveat

However, if we are constructing several of these at once, while each one individually may work 95% of the time, having all of them ‚Äúwork‚Äù (simultaneously) is not guaranteed to the same degree. We can fix this **by increasing the multiplier $m$**. We have discussed 3 different approaches above.

\
\

# Lab Exercise

## Pain thresholds

```{r}
pain = read_tsv("https://raw.githubusercontent.com/DATA2002/data/master/blonds.txt")
glimpse(pain)
```

```{r}
pain = pain %>%
    mutate(HairColour = factor(HairColour,
                               levels = c("LightBlond", "DarkBlond", "LightBrunette", "DarkBrunette")))
levels(pain$HairColour)
```

```{r}
pain %>% 
  ggplot() +
  aes(x = HairColour, y = Pain) +
  geom_boxplot() +
  theme_classic()
```

```{r}
pain_sum = pain %>%
    group_by(HairColour) %>%
    summarise(n = n(), ybar = mean(Pain))
pain_sum
```

```{r}
ni = pain_sum %>%
    pull(n)
ybar_i = pain_sum %>%
    pull(ybar)
```

```{r}
pain_aov = aov(Pain ~ HairColour, data = pain)
summary(pain_aov)
```

### 1

```{r}
sig.hat = sqrt(66.8)
sig.hat
```

Note that $RMS = 66.8$ from the ANOVA table above. This is the estimated $\hat{\sigma}$.

Where both sample sizes are 5, the standard error is then

```{r}
se.55 = sig.hat * sqrt(2/5) # sqrt(1/5 + 1/5)
se.55
```

When one sample is 4 and one sample is 5 (i.e. any comparison with LightBrunette), the standard error is

```{r}
se.45 = sig.hat * sqrt((1/5) + (1/4))
se.45
```

### 2

```{r}
diff_mat = outer(ybar_i, ybar_i, "-")
diff_mat
```

We can get a matrix of standard errors using the fancy `outer()` command

```{r}
se.mat = sig.hat * sqrt(outer(1/ni, 1/ni, "+"))
se.mat
```

The ‚Äúratio‚Äù below gives the t-statistics:

```{r}
diff_mat/se.mat
```

### 3

```{r}
upper.tail.area = c(0.05, 0.025, 0.05/6, 0.025/6, 0.01, 0.005, 0.01/6, 0.005/6) # possible adjusted significance levels when k = 6
t.quantile = qt(1 - upper.tail.area, df = 15) # get a quantile value for each adjusted significance level
cbind(upper.tail.area, t.quantile)
```

For a 95% confidence interval, the multiplier is

```{r}
m = qt(1 - 0.025/6, df = 15)
m
```

For a 99% confidence interval, the multiplier is

```{r}
m = qt(1 - 0.005/6, df = 15)
m
```

### 4

Any $t$-statistics bigger (in absolute value) than the 95% multiplier are significant at the 5% level. This includes:

- `LightBrunette--LightBlond`
- `DarkBrunette--LightBlond`

The latter is also bigger than the 99% multiplier, so it is also significant at the 1% level.

### 5

```{r}
library(emmeans)
pain_em = emmeans(pain_aov, ~HairColour)
# pairs(pain_em, adjust = 'bonferroni')
bonf = contrast(pain_em, method = "pairwise", adjust = "bonferroni")
plot(bonf) + theme_bw() + geom_vline(xintercept = 0)
```

## Tablet

```{r}
tablet = read_tsv("https://raw.githubusercontent.com/DATA2002/data/master/tablet1.txt")
glimpse(tablet)
```

```{r}
tabdat = tablet %>%
    pivot_longer(cols = everything(), names_to = "lab", values_to = "measurement")
glimpse(tabdat)
```

```{r}
tabdat %>% 
  ggplot() + 
  aes(x = lab, y = measurement, fill = lab) + 
  geom_boxplot() + 
  theme_classic() + 
  labs(y = "Chlorpheniramine maleate (mg)",
       x = "Lab", fill = "")
```

### 1

```{r}
t.test(tablet$Lab1, mu = 4)
```

One sample $t$-test. $H_0:\mu_1 = 4 \ \ \text{vs}\ \ H_1: \mu_1 \ne 4$.

### 2

```{r}
t.test(tablet$Lab1, tablet$Lab3)
```

Two sample $t$-test. $H_0:\mu_1 = \mu_3 \ \ \text{vs}\ \ H_1: \mu_1 \ne \mu_3$.

### 3

```{r}
lab_anova = aov(measurement ~ lab, data = tabdat)
summary(lab_anova)
```

1. **Hypotheses**
$$H_0:\mu_1=\mu_2=\mu_3=\mu_4=\mu_5=\mu_6=\mu_7\ \ \text{vs}\ \ H_1: \text{at least one}\ \mu_i\ne\mu_j$$

2. **Assumptions**

- Observations are independent within each of the 7 samples
- Each of the 7 populations have the same variance: $\sigma^2_1=\sigma^2_2=\sigma^2_3=\sigma^2_4=\sigma^2_5=\sigma^2_6=\sigma^2_7=\sigma$
- Each of the 7 populations are normally distributed

3. **Observed Test Statistic**

$$t_0 = \frac{0.020790}{0.003673}=5.66$$

4. **P-value**

$$P(T\ge t_0) = P(F_{6,63}\ge 5.66) < 0.001$$

5. **Decision**

|           As the p-value is very small we reject the null hypothesis and conclude that the population mean level of chlorpheniramine maleate of at least one lab is significantly different to the others.

### 4

```{r}
library(ggfortify)
autoplot(lab_anova, which = c(1, 2)) + theme_classic()
```

In the left hand plot, we‚Äôre looking for changes in the spread of the residuals across the range of fitted values. It looks like there might be a bit more variation in the center than at the extremes, but the side by side boxplots earlier showed that the constant variance assumption was more or less OK in that the spreads of data was not wildly different between the labs.

In the right hand plot, there are a few observations at the lower end that deviate from the diagonal line, so the residuals may not be normally distributed. However, the discrepancy is not large and the total sample size is large enough that the central limit theorem will ensure our inferences are at least approximately valid.

We could generate these plots ‚Äúmanually‚Äù by extracting the fitted values and residuals from the ANOVA object.

```{r}
ass_df = data.frame(fitted = lab_anova$fitted.values, # get fitted values
                    resids = lab_anova$residuals) # get residuals

p1 = ass_df %>%
  ggplot() + 
  aes(sample = resids) + # plot residuals
  stat_qq() + # draw dots
  stat_qq_line() + # draw the diagonal line
  theme_classic() +
  labs(x = "Theoretical quantiles", y = "Residuals")

p2 = ass_df %>%
  ggplot() + 
  aes(x = fitted, y = resids) +
  geom_point() + 
  theme_classic() +
  labs(x = "Fitted values", y = "Residuals")

gridExtra::grid.arrange(p2, p1, ncol = 2)
```

### 5

```{r}
lab_em = emmeans(lab_anova, ~ lab)

lab_pair = contrast(lab_em, method = "pairwise", adjust = "bonferroni")

lab_pair %>% 
  data.frame() %>% 
  filter(p.value < 0.1) %>%
  knitr::kable(digits = 4)
```

```{r}
plot(lab_pair) + 
  theme_bw() + 
  labs(x = "Pairwise mean difference") + 
  geom_vline(xintercept = 0)
```

### 6

#### Kruskal-Wallis Test

üëâ Used when the normality assumption doesn't hold.

**Workflow**

1. Combine the data.

2. With this new pooled data, rank the observations and assign global ranks to the corresponding observations.

3. Assuming observations are independent of each other and different groups follow the same distribution, perform the usual ANOVA $F$-test on the ranks.

```{r}
kruskal.test(measurement ~ factor(lab), data = tabdat)
```

1. **Hypotheses**
$H_0:\text{the level of chlorpheniramine maleate is distributed identically for across all labs (and therefore the mean level is the same across all labs)}$
\
           $H_1: \text{the level of chlorpheniramine maleate is systematically higher for at least one lab}$

2. **Assumptions**

- Observations are independent within each group and groups are independent of each other.
- The different groups follow the same distribution (differing only by the location parameter).

3. **Test Statistic**

$$T=\frac{\text{Treatment SS of the ranks}}{\text{Variance of all the ranks}} \sim \chi^2_{g-1} \ \ \text{under}\ H_0$$ 

4. **Observed Test Statistic**

$$t_0 = 29.606$$

5. **P-value**

$$P(T\ge t_0) = P(\chi^2_6\ge 29.606) < 0.001$$

6. **Decision**

|           As the p-value is very small we reject the null hypothesis and conclude that the population mean of at least one group is significantly different to the others.

#### Post hoc tests

If we wanted to go on and perform nonparametric post hoc tests, we could apply the Bonferroni method to all pairwise comparisons tested by Wilcoxon rank-sum tests.

```{r}
pairwise.wilcox.test(x = tabdat$measurement, g = factor(tabdat$lab), p.adjust.method = "bonferroni")
```

Again, we see that Lab 1 is significantly different to Labs 4, 5 and 6. However, now Lab 3 is also significantly different to Lab 4.

#### Final comments

The Kruskal-Wallis test makes no assumption of normality and thus has a wider range of applicability than a standard one-way ANOVA. It is especially useful in small-sample situations. Because data are replaced by their ranks, outliers will have less influence on this nonparametric test than on the ANOVA test. In some applications, the data might be considered more like a ranking than a measurement - for example, in wine tasting, judges often rank the wines - which makes the use of the rank based tests very natural.

### 7

```{r}
B = 2000
f_stat = vector(mode = "numeric", length = B)
for (i in 1:B) {
    permuted_anova = aov(sample(tabdat$measurement) ~ factor(tabdat$lab)) # perform the ANOVA F-test on the permuted data 
    f_stat[i] = broom::tidy(permuted_anova)$statistic[1] # extract the F-test statistic
}
t_0 = broom::tidy(lab_anova)$statistic[1]
hist(f_stat)
```

```{r}
mean(f_stat >= t_0)
```

