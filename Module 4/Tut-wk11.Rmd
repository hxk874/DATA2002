---
title: "Week 11 Lab"
date: "`r Sys.Date()`"
author: "Tutor: Sanghyun Kim"
output: 
  html_document: 
    ### IMPORTANT ###
    # self_contained: true # Creates a single HTML file as output
    code_folding: hide # Code folding; allows you to show/hide code chunks
    ### USEFUL ###
    code_download: true # Includes a menu to download the code file
    ### OPTIONAL ###
    df_print: paged # Sets how dataframes are automatically printed
    theme: readable # Controls the font, colours, etc.
    toc: true # (Useful) Creates a table of contents!
    toc_float: true # table of contents at the side
    number_sections: false # (Optional) Puts numbers next to heading/subheadings
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
```

```{r}
library(tidyverse)
```

# Lecture recap

## Linear regression

**Goal**

Predict a quantitative response variable $y$ using predictors (can be both quantitative and qualitative) in a way that *it minimises prediction errors* (the difference between actual $y$ values and predictions. It can be measured by R-squared and RMSE)

⚠️ Note: if you're using categorical (qualitative) predictors, make sure to interpret coefficients in terms of the baseline!

**Assumptions**

1. Linearity: linear relationship between the dependent variable and indepedent variables (predictors)

2. Normality: normality of *errors*

3. Homoskedasticity: constant error variance

4. Independence: samples must be independent of each other

# Lab Exercise

## Wind

```{r}
pollut = read.csv("https://raw.githubusercontent.com/DATA2002/data/master/pollut.txt")
glimpse(pollut)
```

### 1

```{r}
# pairs(pollut)
library(GGally)
ggpairs(pollut) + theme_bw()
```

### 2

```{r}
pollut_lm = lm(O ~ ., pollut)
# Or pollut_lm = lm(O ~ WS + Temp + H + In, pollut)
summary(pollut_lm)
```

### 3

Yes, both humidity and insolation are individually insignificant at the 5% level of significance. We can’t immediately drop both of them from the model as the p-values are only testing individual coefficients. If we were to drop one first, we would drop insolation as it has the largest p-value.

We can do a formal test to see if the coefficient of insolation is significant as follows.

First we define the model with population parameters:

$$\text{O} = \beta_0 + \beta_1\text{WS} + \beta_2\text{Temp} + \beta_3\text{H} + \beta_4\text{In} + \epsilon$$

**1. Hypothesis**

$$H_0:\beta_4 = 0\ \ \ \text{vs}\ \ \ H_1: \beta_4 \ne 0$$

**2. Assumptions**

- Residuals $\epsilon_i$ are $\text{i.i.d}\ N(0,\sigma^2)$
- Linear relationship between $x$ and $y$

```{r}
library(ggfortify)
autoplot(pollut_lm, which = 1:2) + theme_bw()
```

- Linearity: there’s no obvious pattern in the residual vs fitted values plot (e.g. no smiley face of frowny face) so it doesn’t appear that we have misspecified the model

- Homoskedasticity: the residuals don’t appear to be fanning out or changing their variability over the range of the fitted values so the constant error variance assumption is met.

- Normality: in the QQ plot, the points are reasonably close to the diagonal line. The bottom 7 or so points are not quite on the line, but it’s not severe enough departure to cause too much concern. The normality assumption is at least approximately satisfied.

**3. Test Statistic**

$$T = \frac{\hat{\beta}_4}{\text{SE}(\hat{\beta}_4)}\sim t_{n-p}\ \ \text{under}\ H_0$$

**4. Observed Test Statistic**

$$t_0 = \frac{0.02275}{0.05067}=0.449\sim t_{25}\ \ \text{under}\ H_0$$

**5. P-value**

$$2P(t_{25}\ge|0.449|) = 0.65728$$

**6. Conclusion**
|           Do not reject $H_0$ at the 5% level of significance as the p-value is greater than 0.05. Hence, there is no evidence to suggest that there is a significant linear relationship between ozone and insolation and it can be dropped from the model.

### 4

```{r}
pollut_step = step(pollut_lm) # it gives you the best possible model based on AIC (i.e., the model with the smallest AIC given your data), but it may contain insignificant coeffcients
```

### 5

$$\widehat{\text{Ozone}} = -16.6070 - 0.4420\times\text{WS} + 0.6019\times\text{Temp} + 0.0985\times\text{Humidity}$$

### 6

```{r}
autoplot(pollut_step, which = 1:2) + theme_bw()
```

- Linearity: there’s no obvious pattern in the residual vs fitted values plot (e.g. no smiley face of frowny face) so it doesn’t appear that we have misspecified the model

- Homoskedasticity: the residuals don’t appear to be fanning out or changing their variability over the range of the fitted values so the constant error variance assumption is met.

- Normality: in the QQ plot, the points are reasonably close to the diagonal line. The bottom 7 or so points are not quite on the line, but it’s not severe enough departure to cause too much concern. The normality assumption is at least approximately satisfied.

### 7

```{r}
summary(pollut_step)
```

Looking at the $R^2$ value (multiple R-squared) from the summary output, 80% of the variability of ozone is explained by the regression on wind speed, temperature and humidity.

### 8

```{r}
newdata = data.frame(WS = 40, Temp = 80, H = 50)
predict(pollut_step, newdata, interval = "confidence")
```

```{r}
predict(pollut_step, newdata, interval = "prediction")
```

Using the regression, the estimate average ozone for days when `WS = 40`, `Temp = 80` and `H = 50` is 18.62.

A confidence interval is more appropriate here, because the question asked about estimating the average ozone on days when…..

If instead the question asked: predict the ozone on a day when… we’d use a prediction interval instead.

The 95% confidence interval for the estimated ozone level is (16.71, 20.54).


## Diabetes

```{r}
# install.packages('mplot')
data("diabetes", package = "mplot")
# help('diabetes', package = 'mplot')
```

```{r}
glimpse(diabetes)  # glimpse the structure of the diabetes
pairs(diabetes)  # traditional pairs plot
GGally::ggpairs(diabetes)  # ggplotified pairs plot
boxplot(diabetes)  # always a good idea to check for gross outliers
boxplot(scale(diabetes))  # always a good idea to check for gross outliers
```

```{r}
M0 = lm(y ~ 1, data = diabetes)  # Null model
M1 = lm(y ~ ., data = diabetes)  # Full model
```

```{r}
# stargazer::stargazer(M0, M1, type = 'latex', header = FALSE)
stargazer::stargazer(M0, M1, type = "text")
```

### 1

```{r}
step_back_aic = step(M1, direction = "backward", trace = FALSE)
summary(step_back_aic)
```

### 2

```{r}
step_fwd_aic = step(M0, scope = list(lower = M0, upper = M1), direction = "forward", trace = FALSE)
summary(step_fwd_aic)
```

### 3

```{r}
add1(step_fwd_aic, test = "F", scope = M1)
```

```{r}
drop1(step_fwd_aic, test = "F")
```

### 4

```{r}
drop1(M1, test = "F") # age has the most insignificant p-value
```

```{r}
M2 = update(M1, . ~ . - age) # drop age
drop1(M2, test = "F") # after dropping age, hdl has the most insignificant p-value
```

```{r}
M3 = update(M2, . ~ . - hdl) # drop hdl
drop1(M3, test = "F") # after dropping age and hdl, glu has the most insignificant p-value
```

```{r}
M4 = update(M3, . ~ . - glu) # drop glu
drop1(M4, test = "F") # after dropping, age, hdl and glu, tch has the most insignificant p-value
```

```{r}
M5 = update(M4, . ~ . - tch) # drop tch
drop1(M5, test = "F") # everything is significant at the 5% significance level
```

### 5

```{r}
autoplot(M5, which = 1:2) + theme_bw()
```

There does seem to be some fanning out of the residuals in the residual vs fitted value plot, indicating that there may be some heteroskedasticity in the our data.

In the normal QQ plot, the points are all reasonably close to the diagonal line, therefore we are confident that the normal assumption is at least approximately satisfied.

### 6

```{r}
M5
```

$$\hat{y} = -313.8 - 21.6\times\text{sex} + 5.7\times\text{bmi} + 1.1\times\text{map} - 1.0\times\text{tc} + 0.8\times\text{ldl} + 73.3\times\text{ltg}$$

- On average, holding the other variables constant, a 1  increase in BMI leads to a 5.7 unit increase in diabetes disease progression.
- On average, holding the other variables constant, a 1 mmHg increase in mean arterial blood pressure leads to a 1.1 unit increase in diabetes disease progression.
- On average, holding the other variables constant, a 1 mg/dL increase in total cholesterol leads to a 1.0 unit decrease in diabetes disease progression.
- On average, holding the other variables constant, a 1 mg/dL increase in low density lipoprotein leads to a 0.8 unit increase in diabetes disease progression.
- On average, holding the other variables constant, a 1 mg/dL increase in ltg leads to a 73.3 unit increase in diabetes disease progression.
- On average, the holding the other variables constant, the difference in diabetes disease progression between males and females in 21.6. If male = 1 and female = 2 then we can say that the disease progression is 26.1 units less for females than males.

Note that it doesn’t make sense to interpret the intercept in this model, as values of zero in many of the covariates are not possible.

### 7

```{r}
library(caret)
set.seed(2023)
caret::train(formula(M5), data = diabetes, method = "lm", 
             trControl = trainControl(method = "cv", number = 5))


caret::train(formula(M5), data = diabetes, method = "lm", 
             trControl = trainControl(method = "cv", number = 5))
```

